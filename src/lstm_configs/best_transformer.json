{
    "name": "best_transformer",
    "embedding_dim": 64,
    "hidden_dim": 256,
    "num_layers": 1,
    "dropout": 0.1,
    "bidirectional": false,
    "tgt_emb_prj_weight_sharing": false,
    "positional_encoding": true,
    "attention": true,
    "label_smoothing": 0.1,
    "use_layer_norm": true
}