{
    "activation": "relu",
    "batch_first": true,
    "d_model": 64,
    "dim_feedforward": 256,
    "dropout": 0.1,
    "n_head": 4,
    "n_layers": 2,
    "n_position": 200,
    "name": "OG Transformer",
    "norm_first": true,
    "src_pad_idx": 1188,
    "src_vocab_size": 1260,
    "tgt_pad_idx": 305,
    "tgt_vocab_size": 306
}